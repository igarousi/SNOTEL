{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect the Observed Snow Data using CUAHSI Data Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This noteook retrieves Snow Water Equivalent (SWE) and accumulated precipitation (P) data from SNOTEL sites through CUAHSI data client service.  The notebook has five sections as following:\n",
    "\n",
    "1. Import Libraries\n",
    "2. Visualize Ecoregions\n",
    "3. Define Parameters\n",
    "4. Define Functions \n",
    "5. Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries\n",
    "In this section, required python libraries are installed and imported. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ulmo  \n",
    "import pytz\n",
    "import datetime\n",
    "from timezonefinder import TimezoneFinder\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pylab import *\n",
    "import glob\n",
    "from matplotlib import colors\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "from suds.client import Client\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import Grouper  \n",
    "from datetime import timedelta\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.   Read SNOTEL Information\n",
    "Information includes but not limited to station code, station latitude and longitude, and associated ecoregions provided by the Commission for Environmental Corporation (CEC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "snotel_network = '../input/NRCS_SNOTEL_Joint_w_CEC.csv'  \n",
    "output_dir = '../output'\n",
    "snotel_info = pd.read_csv(os.path.join(os.getcwd(), snotel_network))\n",
    "snotel_info = snotel_info[snotel_info['Join_Count'] == 1]                 # To make sure only those associated with CEC are used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.   Define Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following parameters identify the name of the network from which we want to retrieve data. It also creates the CUAHSI link to the defined network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start preparing input arguments that are required when connecting to CUAHSI data client service\n",
    "network = \"SNOTEL\"     \n",
    "wsdl = f'http://hydroportal.cuahsi.org/{network.lower()}/cuahsi_1_1.asmx?WSDL'\n",
    "client = Client(wsdl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.   Define Functions\n",
    "Two functions are defined in this Jupyter Notebook. *DataFrame* and *Local2UTC*.  The first function is used to retrieve SNOTEL data.  The second function is used when we want to transform local time to UTC time.  \n",
    "\n",
    "- **DataFrame**: This function creates a dataframe for retrieved data including retrieved information. \n",
    "\n",
    "\n",
    "- **Local2UTC**: There are two different time zones within these ecoregions, Mountain Time and Pacific Time zones.  'America/Phoenix', is in the Mountain Time zone and does not observe daylight saving time.  It always has 7 hours offset from UTC.  'America/Boise' and 'America/Denver' are also in the Mountain Time zone with 6 hours offset from UTC during daylight saving time and 7 hours offset in standard time.  'America/Los_Angeles' is in the Pacific Time with 7 hours offset from UTC during daylight saving time and 8 hours ofset in standard time.  These are important when comparing daily average values of SNOTEL with hourly datasets such as NWM where outputs are in UTC time or SNODAS snapshots that are reported at 6:00 UTC.  The Local2UTC function takes a dataframe that has a column called 'date' (showing the local time for each record (row)) and a list of integer indices of the dataframe as inputs.  The function runs over each row of the dataframe and reads corresponding latitude and longitude values to get the name of the time zone ('America/Phoenix', America/Boise', 'America/Denver', or 'America/Los_Angeles').  Then, it uses pytz library and and transform the local date/time to a UTC date/time.  The next part checks for the offset value and updates the time for the local time that by default is 00:00:00.  This update helps to choose a time for SNOTEL local time that is equivalent to 6:00 UTC (as used in SNODAS outputs).\n",
    "\n",
    "\n",
    "- **Data_Retrieval**: This function uses snotel information (csv file), DataFrame, and Local2UTC functions to retrieve SNOTEL data from CUAHSI data client service. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to make a dataframe from retrieved data.  \n",
    "# This function can be used for both SWE and Precipitation retrievals.\n",
    "\n",
    "def DataFrame(self, st, et):\n",
    "    \n",
    "    # series info\n",
    "    qo = self.queryInfo\n",
    "    self.site_code = qo.criteria.locationParam\n",
    "    self.variable_code = qo.criteria.variableParam\n",
    "    self.start = st \n",
    "    self.end = et \n",
    "\n",
    "    # source info\n",
    "    si = self.timeSeries[0].sourceInfo\n",
    "    self.site_name = si.siteName\n",
    "    self.latitude = si.geoLocation.geogLocation.latitude\n",
    "    self.longitude = si.geoLocation.geogLocation.longitude\n",
    "    \n",
    "    # variable\n",
    "    v = self.timeSeries[0].variable\n",
    "    self.variable_name = v.variableName\n",
    "    self.variable_datatype = v.dataType\n",
    "    self.units_abbv = v.unit.unitAbbreviation\n",
    "    self.nodata = v.noDataValue\n",
    "\n",
    "    # values\n",
    "    self.data = []\n",
    "    for val in self.timeSeries[0].values[0].value:\n",
    "        value_dt  = val._dateTime\n",
    "        value_in = float(val.value)\n",
    "        if value_in != self.nodata:\n",
    "            value_mm = value_in * 25.4\n",
    "        else:\n",
    "            value_in = np.NaN\n",
    "            value_mm = np.NaN\n",
    "        self.data.append(dict(date=value_dt,\n",
    "                              value_inches=value_in,\n",
    "                              value_mm=value_mm))\n",
    "     \n",
    "    atts = {k:v for k,v in self.__dict__.items()}\n",
    "\n",
    "    dat = []\n",
    "    for val in self.data:\n",
    "        content = {k:v for k,v in atts.items()}\n",
    "        for k, v in val.items():\n",
    "            content[k] = v\n",
    "        dat.append(content)  \n",
    "\n",
    "    df = pd.DataFrame(dat)\n",
    "    df = df.set_index(df.date)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that transform local time to UTC.\n",
    "\n",
    "def Local2UTC(data, indices):\n",
    "    \n",
    "    tf = TimezoneFinder()\n",
    "\n",
    "    LOCAL = []\n",
    "    UTC = []\n",
    "    \n",
    "    # Loop over each row of the dataframe    \n",
    "    for row in indices:\n",
    "                \n",
    "        timezone_str = tf.timezone_at(lng=data.longitude[row], lat=data.latitude[row])\n",
    "        local_time = pytz.timezone(timezone_str)\n",
    "        # The next line uses the date and by default gives the time 00:00:00 \n",
    "        # (i.e., 12:00 am) to the datetime object\n",
    "        naive_datetime = datetime.strptime(data['date'][row].strftime('%Y-%m-%d %H:%M:%S'), \"%Y-%m-%d %H:%M:%S\") \n",
    "        local_datetime = local_time.localize(naive_datetime, is_dst=None)\n",
    "        utc_datetime = local_datetime.astimezone(pytz.utc)\n",
    "        \n",
    "        # Update naive_time based on timezone. This update helps to choose a \n",
    "        # time for SNOTEL daily values that are equivalent to 6:00 am UTC\n",
    "        \n",
    "        # Condition 1: if (local_time == \"America/Phoenix\") or \n",
    "        # (local_time == \"America/Denver\" and utc_datetime.hour == 7, Standard) or\n",
    "        # (local_time == \"America/Boise\" and utc_datetime.hour == 7, Standard) or\n",
    "        # (local_time == \"America/Los_Angeles\" and utc_datetime.hour == 7, Daylight)\n",
    "        if utc_datetime.hour == 7:\n",
    "            naive_datetime = naive_datetime + timedelta(hours=23)\n",
    "            local_datetime = local_time.localize(naive_datetime, is_dst=None)\n",
    "            utc_datetime = local_datetime.astimezone(pytz.utc)\n",
    "            utc_datetime_str = utc_datetime.strftime (\"%Y-%m-%d %H:%M:%S\")\n",
    "            \n",
    "        # Condition 2: if (local_time == \"America/Denver\" and utc_datetime.hour == 6, Daylight) or\n",
    "        # (local_time == \"America/Boise\" and utc_datetime.hour == 6, Daylight)\n",
    "        elif utc_datetime.hour == 6: \n",
    "            naive_datetime = naive_datetime\n",
    "            local_datetime = local_time.localize(naive_datetime, is_dst=None)\n",
    "            utc_datetime = local_datetime.astimezone(pytz.utc)\n",
    "            utc_datetime_str = utc_datetime.strftime (\"%Y-%m-%d %H:%M:%S\")\n",
    "            \n",
    "        # Condition 3: if (local_time == \"America/Los_Angeles\" and utc_datetime.hour == 8, Standard)\n",
    "        elif utc_datetime.hour == 8: \n",
    "            naive_datetime = naive_datetime + timedelta(hours=22)\n",
    "            local_datetime = local_time.localize(naive_datetime, is_dst=None)\n",
    "            utc_datetime = local_datetime.astimezone(pytz.utc)\n",
    "            utc_datetime_str = utc_datetime.strftime (\"%Y-%m-%d %H:%M:%S\")\n",
    "            \n",
    "        \n",
    "        LOCAL.append(local_datetime)\n",
    "        UTC.append(utc_datetime_str)\n",
    "        \n",
    "        \n",
    "    # Add columns to the dataframe\n",
    "    data['datetime_LOCAL'] = LOCAL\n",
    "    data['datetime_UTC'] = UTC\n",
    "        \n",
    "    # Add UTC times to index\n",
    "    data.index = data['datetime_UTC']\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that retrieves data from CUAHSI data services.\n",
    "\n",
    "def Data_Retrieval(info_dataframe, variable, abbr, output_dir, output_name):\n",
    "    \n",
    "    site_code = info_dataframe['Station_ID']\n",
    "    variable_code_daily = f'{network}:{variable}'\n",
    "    var_Daily = pd.DataFrame([])\n",
    "    \n",
    "    \n",
    "    for i in range(0, len(site_code)):\n",
    "        \n",
    "        code = f'{site_code[0]}_{info_dataframe[\"State\"][0]}_SNTL'\n",
    "        sitecode = f'{network}:{code}'\n",
    "        site = ulmo.cuahsi.wof.get_site_info(wsdl, sitecode, suds_cache=('default', ))    \n",
    "        sc = f'{network}:{site[\"code\"]}'   \n",
    "        st = datetime.strptime(site['site_property']['site_comments'].split('|')[0].split('=')[1].split(' ')[0], '%m/%d/%Y')  \n",
    "        et = datetime.strptime(site['site_property']['site_comments'].split('|')[1].split('=')[1].split(' ')[0], '%m/%d/%Y')\n",
    "    \n",
    "    \n",
    "        try:\n",
    "            temp = client.service.GetValuesObject(sc, variable_code_daily, st, et, '')\n",
    "            # Use DataFrame function defined above\n",
    "            temp_df = DataFrame(temp, st, et)\n",
    "            var_Daily = var_Daily.append(temp_df, ignore_index=True)\n",
    "            print(i, sc, st, et)  \n",
    "        except Exception as error:\n",
    "            print(\"==========================================================\")\n",
    "            print(f'{variable} at {sc} with index {i} in site_code is not available.')\n",
    "            print(\"==========================================================\")\n",
    "            pass\n",
    "        \n",
    "        \n",
    "    Daily_small_df = pd.DataFrame({'col1':var_Daily['site_code'], \n",
    "                                   'col2':var_Daily['site_name'], \n",
    "                                   'col3':var_Daily['date'], \n",
    "                                   'col4':var_Daily['value_inches'],\n",
    "                                   'col5':var_Daily['value_mm'],\n",
    "                                   'col6':var_Daily['latitude'],\n",
    "                                   'col7':var_Daily['longitude']}) \n",
    "              \n",
    "    \n",
    "    Daily_small_df.columns = ['site_code', 'site_name', 'date', f'{abbr}_inches', \n",
    "                               f'{abbr}_mm', 'latitude', 'longitude']\n",
    "\n",
    "\n",
    "    info_dataframe = info_dataframe.reset_index()\n",
    "    for c in range (0, len(site_code)):\n",
    "        Daily_small_df.loc[Daily_small_df['site_name'] == info_dataframe['Station_Na'][c], 'name'] = info_dataframe['NAME'][c]\n",
    "        \n",
    "        \n",
    "    # Run Local2UTC function defined above\n",
    "    Daily_small_df_utc = Local2UTC(Daily_small_df, Daily_small_df.index)\n",
    "        \n",
    "        \n",
    "    # Save results as a CSV file\n",
    "    Daily_small_df_utc.to_csv(f'{output_dir}/{output_name}', index=False)\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.   Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following retrieves all available snow water equivalent (SWE) and precipitation data for all gages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 SNOTEL:301_CA_SNTL 1983-10-01 00:00:00 2100-01-01 00:00:00\n",
      "1 SNOTEL:301_CA_SNTL 1983-10-01 00:00:00 2100-01-01 00:00:00\n",
      "2 SNOTEL:301_CA_SNTL 1983-10-01 00:00:00 2100-01-01 00:00:00\n",
      "3 SNOTEL:301_CA_SNTL 1983-10-01 00:00:00 2100-01-01 00:00:00\n",
      "4 SNOTEL:301_CA_SNTL 1983-10-01 00:00:00 2100-01-01 00:00:00\n",
      "5 SNOTEL:301_CA_SNTL 1983-10-01 00:00:00 2100-01-01 00:00:00\n",
      "6 SNOTEL:301_CA_SNTL 1983-10-01 00:00:00 2100-01-01 00:00:00\n",
      "7 SNOTEL:301_CA_SNTL 1983-10-01 00:00:00 2100-01-01 00:00:00\n",
      "8 SNOTEL:301_CA_SNTL 1983-10-01 00:00:00 2100-01-01 00:00:00\n",
      "9 SNOTEL:301_CA_SNTL 1983-10-01 00:00:00 2100-01-01 00:00:00\n",
      "10 SNOTEL:301_CA_SNTL 1983-10-01 00:00:00 2100-01-01 00:00:00\n",
      "11 SNOTEL:301_CA_SNTL 1983-10-01 00:00:00 2100-01-01 00:00:00\n",
      "12 SNOTEL:301_CA_SNTL 1983-10-01 00:00:00 2100-01-01 00:00:00\n",
      "13 SNOTEL:301_CA_SNTL 1983-10-01 00:00:00 2100-01-01 00:00:00\n",
      "14 SNOTEL:301_CA_SNTL 1983-10-01 00:00:00 2100-01-01 00:00:00\n",
      "15 SNOTEL:301_CA_SNTL 1983-10-01 00:00:00 2100-01-01 00:00:00\n",
      "16 SNOTEL:301_CA_SNTL 1983-10-01 00:00:00 2100-01-01 00:00:00\n",
      "17 SNOTEL:301_CA_SNTL 1983-10-01 00:00:00 2100-01-01 00:00:00\n",
      "18 SNOTEL:301_CA_SNTL 1983-10-01 00:00:00 2100-01-01 00:00:00\n",
      "19 SNOTEL:301_CA_SNTL 1983-10-01 00:00:00 2100-01-01 00:00:00\n",
      "20 SNOTEL:301_CA_SNTL 1983-10-01 00:00:00 2100-01-01 00:00:00\n",
      "21 SNOTEL:301_CA_SNTL 1983-10-01 00:00:00 2100-01-01 00:00:00\n",
      "22 SNOTEL:301_CA_SNTL 1983-10-01 00:00:00 2100-01-01 00:00:00\n",
      "23 SNOTEL:301_CA_SNTL 1983-10-01 00:00:00 2100-01-01 00:00:00\n",
      "24 SNOTEL:301_CA_SNTL 1983-10-01 00:00:00 2100-01-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Data_Retrieval(snotel_info, 'WTEQ_D', 'swe', output_dir, 'SNOTEL_SWE.csv')\n",
    "Data_Retrieval(snotel_info, 'PREC_D', 'precip', output_dir, 'SNOTEL_P.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snotel",
   "language": "python",
   "name": "snotel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
